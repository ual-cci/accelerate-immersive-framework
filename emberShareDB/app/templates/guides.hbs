{{#if isGuide}}
<div id = "tutorial-container">
<h1> Guide to {{model.name}} </h1>
{{#if isMMLL}}
<p class = "tutorial-text">
Machine listening is the attempt to make computers hear sound intelligently. We often emulate the human hearing system, though engineering may not mirror human anatomy, and may deviate from physiological function, including purely mathematical algorithms to extract some sort of further information from audio signals. The interest of the MIMIC project is in musical machine listening, that is, the computer understanding of musical audio signals, and the Musical Machine Listening Library introduced here (subsequently MMLL) is a javascript library to do just that, in the web browser.
</p>

<p class = "tutorial-text">
The library provides a variety of higher level musical listening facilities for computer music, such as onset detection, chord detection, beat tracking and auditory modelling. All the listening objects can run live, to benefit the creation of interative music systems and live electronic music compositions. They can also render audio faster than realtime if called outside of a live processing callback, suitable for the analysis of audio files for machine learning purposes. The library also includes analysis and resynthesis capability from the inverse Fourier transform and via the tracking phase vocoder (which identifies sinusoidal partial trails within audio signals).
</p>

<p class = "tutorial-text">
The first embeded example here is a feature extractor from live audio. You can choose as input either a sound file from your hard drive, or an attached microphone. Note that you will need to give permission for the microphone to run within a web browser, for security reasons. A single feature is extracted, the Sensory Dissonance (how rough sounding tha audio is, according to a perceptual model). If you selected an audio file, it will play back, but if you selected microphone the output audio will be silent to avoid feedback.
</p>

<iframe class = "embedded-tutorial-code" src={{concat url "/code/f6a258e2-35c4-6b08-0bbf-07f334de613a?embed=true&showCode=true" allow="microphone" scrolling="no"}} style="width: 100%; height: 350px; overflow: hidden;">what?</iframe>
<p class = "tutorial-text">
<a href = {{concat url "/code/f6a258e2-35c4-6b08-0bbf-07f334de613a"}}>Open Project</a>
</p>
<p class = "tutorial-text">
The second embeded example is a live spectral view, showing the results of a Fast Fourier Transform of successive snapshots of the input signal. The power spectrum and phase spectrum are both plotted, in linear frequency range. Most of the activity will tend to be on the left of the plot of the power spectrum, for normal audio sources, whose spectral content tends to drop off for higher frequencies. You can choose the gain for the output to hear or not hear the source signal (the default is silence).
</p>

<p><iframe class = "embedded-tutorial-code" src={{concat url "/code/38c2887a-f8f3-5959-324c-7c0f176c0db7?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height:350px; overflow: hidden;">what?</iframe></p>
<p class = "tutorial-text">
<a href = {{concat url "/code/38c2887a-f8f3-5959-324c-7c0f176c0db7"}}>Open Project</a>
</p>
<p class = "tutorial-text">
The third embeded example is an onset detector, which reacts to percussive events in the input signal. If you are using live microphone near a speaker you may find headphones work best, to avoid feedback effects. An onset is indicated by a flashing colour change; changing the threshold adjusts the sensitivity of detection.
</p>

<p><iframe class = "embedded-tutorial-code" src={{concat url "/code/fcdf62d8-a47b-1ddf-f16a-9cd09b328a65?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 350px; overflow: hidden;">what?</iframe></p>
<p class = "tutorial-text">
<a href = {{concat url "/code/fcdf62d8-a47b-1ddf-f16a-9cd09b328a65"}}>Open Project</a>
</p>
<p class = "tutorial-text">
Once an input sound is analysed, you can synthesize output based on the features, work with machine learning to further classify or process inputs based on the features,and make generally responsive and interactive music systems for concerts, installations, websites, etc
</p>


<p class = "tutorial-text">
  MMLL was developed by <a href="http://composerprogrammer.com/index.html">Nick Collins</a> as part of the AHRC funded MIMIC project (Musically Intelligent Machines Interacting Creatively). MMLL is released under an MIT license, see the included COPYING.txt file. The source code is available at <a href="https://github.com/sicklincoln/MMLL">github</a> though you can use it straight away from a web page just by linking to the <a href="https://raw.githubusercontent.com/sicklincoln/MMLL/master/MMLL.js">MMLL.js</a> source code file. The Examples folder provides a test example for each listener currently available in the library.</p>

<p class = "tutorial-text">Some more developed examples available on codecircle are linked now.</p>

<p class = "tutorial-text">Spectral delay based on spectral resynthesis. The input is analysed by FFT, then particular spectral bins can be independently delayed and fed back on themselves to make a diffuse delayed filterbank.</p>

<iframe class = "embedded-tutorial-code" src={{concat url "/code/d5499af6-f4f3-2683-0c05-b700f1a9f1b1?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 650px; overflow: hidden;">what?</iframe>
<p class = "tutorial-text">
<a href = {{concat url "/code/d5499af6-f4f3-2683-0c05-b700f1a9f1b1"}}>Open Project</a>
</p>
<p class = "tutorial-text">bbcut, based on beat tracking. The input is cut up live into stuttering buffers, with the cut points determined by tracking of the primary metrical level in the music.</p>

<p class = "tutorial-text"><iframe class = "embedded-tutorial-code" src={{concat url "/code/5ed346fe-f7d5-b7ce-87a4-df6e352dbb4a?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 550px;  overflow: hidden;">what?</iframe></p>
<p class = "tutorial-text">
<a href = {{concat url "/code/5ed346fe-f7d5-b7ce-87a4-df6e352dbb4a"}}>Open Project</a>
</p>
{{/if}}
{{#if isEvolib}}

<p class = "tutorial-text">
How about using a machine intelligence technique to help us to program a modular synthesizer? In this guide, we'll show you how.
</p>
<h2>
Introduction
</h2>
<p class = "tutorial-text">
A lot of recent machine learning systems that you may have read about use things called deep neural networks to do creative things like writing music, generating images and so on. But there are many other techniques used to allow computers to do seemingly smart things. One of these is called a genetic algorithm. With genetic algorithms, we can actually breed things inside a computer, just like we might breed new varieties of crops or animals. The idea is to work with a small population of things (in this case, sounds) which we are going breed and mutate until we are satisfied with the results.
</p>
<p class = "tutorial-text">
In this example, we are going to use a genetic algorithm to breed virtual modular synthesizer patches. We have created a simple Javascript library for you called Evolib that makes this possible.
</p>
<h2>
Part 1: getting started - make a sound
</h2>
<p class = "tutorial-text">
Let's get started by creating a random synthesizer patch, then we'll find out how to improve it through selective breeding.
</p>
<p class = "tutorial-text">
Here is some starter code which just pulls in the evolib library. You'll need to upload evolib.js as a file asset:
</p>
<pre>
<code>
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;script src="evolib.js"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;/body&gt;
&lt;/html&gt;
</code>
</pre>
<p class = "tutorial-text">
Now we are ready to tell evolib to make some sounds. Put this code in the body tag somewhere - this creates a new population of 5 sounds, each sound has 30 modules. The modules might be oscillators or filters, and can be wired to eachother in different ways. The modules and wiring starts off totally random.
</p>
<pre>
  <code>
&lt;script language="javascript" type="text/javascript"&gt;
Evolib.newPopulation(5, 30); // 5 sounds, 30 modules each
&lt;/script&gt;
</code>
</pre>
<p class = "tutorial-text">
Now we want to listen to our sounds.
</p>
<p class = "tutorial-text">
Web browsers don't let us play any sound unless the user has clicked on something first. To listen to one of the sounds then, we need to add a button and tell it what to do when they click it.
</p>
<p class = "tutorial-text">
Add this to the body tag:

<pre>
  <code>
&lt;button onclick="Evolib.play(0)"&gt;Listen to sound 0&lt;/button&gt;
</code>
</pre>
<p class = "tutorial-text">
Now how about another button to stop the sound?
</p>

<pre>
  <code>
&lt;button onclick="Evolib.stop(0)"&gt;Stop the sound&lt;/button&gt;
</code>
</pre>
<p class = "tutorial-text">
Sometimes, the sounds are silent. Imagine if you randomly wired up 30 randomly selected oscillators and filters - would it always make a sound? Let's add another button that let's us generate a new random sound easily so we can keep pressing it until we get a decent sound.
</p>
<pre>
  <code>
&lt;button onclick="Evolib.newPopulation(5, 30);  Evolib.play(0)"&gt;new sound&lt;/button&gt;
</code>
</pre>
<p class = "tutorial-text">
Note that this button generates a new population, then plays the first sound.
</p>
<p class = "tutorial-text">
Here is the complete code so far
</p>
<p class = "tutorial-text">
  <iframe class = "embedded-tutorial-code" src={{concat url "/code/a990f234-5769-c556-b49a-0154204a016a?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 350px; overflow: hidden;">what?</iframe>
<a href = {{concat url "/code/a990f234-5769-c556-b49a-0154204a016a"}}>Open Project</a>
</p>
<h2>
Part 2: mutate the sound
</h2>
<p class = "tutorial-text">
Now we have some neat sounds, we are going to start using evolutionary computation to mutate them. Let's get straight to mutating sounds, then we'll think about what is going on.
</p>
<p class = "tutorial-text">
Add this to your set of buttons:
</p>
<pre>
  <code>
  &lt;button
   onclick="Evolib.evolve([0], 0.1);Evolib.play(0)"&gt;
     mutate
  &lt;/button&gt;
</code>
</pre>
Try clicking the new sound button until you get a decent sound. Then click on mutate repeatedly, and you should hear the sound changing slightly. This is the sound being mutated.

The important code here is the call to Evolib.evolve:
<pre>
  <code>
Evolib.evolve([0], 0.1);
</code>
</pre>
</p>
<p class = "tutorial-text">
It takes two arguments - the first is a list of numbers (in this case, just 0) which are the sounds we want to 'evolve'. The second is the mutation rate. The higher the mutation rate, the more the sound will change each time you mutate it.
</p>
<p class = "tutorial-text">
The power of genetic algorithms lies in the fact that they represent the things you are evolving in a form that can be mutated, and even crossed with other things. This is very similar to how plants and animals are described in their DNA and changing the DNA changes the plant or the animal.
</p>
<p class = "tutorial-text">
The DNA of an evolib sound is a list of numbers, like this: 0.5, 0.125, 0.255 etc. One number might say what kind of module it is (&lt; 0.5? its a filter. &gt;= 0.5? its an oscillator). Another number might set up the initial state of the module, e.g. the filter cutoff frequency (0-5000Hz). Other numbers describe how that module should be wired to other modules, by specifying a connection range.
</p>
<p class = "tutorial-text">
Here is the complete code:
</p>
<p class = "tutorial-text">
  <iframe class = "embedded-tutorial-code" src={{concat url "/code/3afdc780-e5f8-3ff1-0e31-eb76859c6703?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 350px; overflow: hidden;">what?</iframe>
<a href = {{concat url "/code/3afdc780-e5f8-3ff1-0e31-eb76859c6703"}}>Open Project</a>
</p>
<h2>
Part 3: selecting sounds for breeding
</h2>
<p class = "tutorial-text">
So far, we have only been working with a single sound and mutating it. Now we are going to get access to a population of sounds, so we can choose which mutant we want to breed from.
</p>
<p class = "tutorial-text">
Try adding some more play buttons to the program, so your play buttons look like this:
</p>
<pre>
  <code>
  &lt;button onclick="Evolib.play(0)"br&gt;play 1&lt;/buttonbr&gt;
&lt;br&gt;
  &lt;button onclick="Evolib.play(1)"br&gt;play 1&lt;/buttonbr&gt;
&lt;brbr&gt;
  &lt;button onclick="Evolib.play(2)"br&gt;play 1&lt;/buttonbr&gt;
&lt;brbr&gt;
  &lt;button onclick="Evolib.play(3)"br&gt;play 2&lt;/buttonbr&gt;
&lt;brbr&gt;
  &lt;button onclick="Evolib.play(4)"br&gt;play 3&lt;/buttonbr&gt;
</code>
</pre>
<p class = "tutorial-text">
Now you can listen to all 5 sounds in the population. Try clicking the buttons. You will hear that they all sound different. That is because they are all random sounds.
</p>
<p class = "tutorial-text">
Now let's add buttons which allow us to choose which sound we want to create the next population from, for example this one selects sound 1 for mutation:
</p>
<pre>
  <code>
  &lt;button onclick="Evolib.play(1)"br&gt;play 1&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.evolve([1], 0.1);Evolib.play(0)"br&gt;mutate&lt;/buttonbr&gt;
</code>
</pre>
<p class = "tutorial-text">
You'll end up with something like this, which shows the full set of buttons:
</p>
<pre>
  <code>
  &lt;button onclick="Evolib.play(0)"br&gt;play 0&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.evolve([0], 0.1);Evolib.play(0)"&gt;mutate&lt;/buttonbr&gt;
  &lt;brbr&gt;
  &lt;button onclick="Evolib.play(1)"&gt;play 1&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.evolve([1], 0.1);Evolib.play(0)"&gt;mutate&lt;/buttonbr&gt;
  &lt;brbr&gt;
  &lt;button onclick="Evolib.play(2)"&gt;play 2&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.evolve([2], 0.1);Evolib.play(0)"&gt;mutate&lt;/buttonbr&gt;
  &lt;brbr&gt;
  &lt;button onclick="Evolib.play(3)"&gt;play 3&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.evolve([3], 0.1);Evolib.play(0)"&gt;mutate&lt;/buttonbr&gt;
  &lt;brbr&gt;
  &lt;button onclick="Evolib.play(4)"&gt;play 4&lt;/buttonbr&gt;
    &lt;button onclick="Evolib.evolve([4], 0.1);Evolib.play(0)"&gt;mutate&lt;/buttonbr&gt;
&lt;brbr&gt;
  &lt;brbr&gt;
  &lt;button onclick="Evolib.stop()"&gt;stop&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.newPopulation(5, 30);  Evolib.play(0)"&gt;new sounds&lt;/buttonbr&gt;
</code>
</pre>
<p class = "tutorial-text">
Now you can click on the mutate button to select which of the sounds you want. After clicking mutate, click on the play buttons to hear mutations of the sound you selected for mutation. Keep going and you'll gradually breed a set of sounds. If they change too little, increase the mutation rate:
</p>
<pre>
  <code>
Evolib.evolve([0], 0.2); // 0.2 is a higher mutation rate
</code>
</pre>
<p class = "tutorial-text">
Here is the complete code:
</p>
<p class = "tutorial-text">
  <iframe class = "embedded-tutorial-code" src={{concat url "/code/723f4078-b9c2-de8d-4970-fb41609213e2?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 350px; overflow: hidden;">what?</iframe>
<a href = {{concat url "/723f4078-b9c2-de8d-4970-fb41609213e2"}}>Open Project</a>
</p>
<h2>
Next part:
</h2>
<p class = "tutorial-text">
In the next part, we'll look at how to add a record button, how to gain more control of the evolutionary process and how to change the characteristics of the available modules.
</p>

{{/if}}
</div>
{{else}}

{{#each model as |guide|}}
  <a href = {{guide.url}}>{{guide.name}}</a><br>
{{/each}}
{{/if}}
