{{#if isGuide}}
<div id = "tutorial-container">
<h1> Guide to {{model.name}} </h1>
{{#if isKadenze}}
<p class = "tutorial-text">
  Rebecca Fiebrink, a key part of the MIMIC team, runs the excellent Kadenze course Machine Learning for Musicians and Artists. It provides a ton of learning resources and is designed to teach machine learning in a way that will be useful to creative pracitioners.
</p>
<p class = "tutorial-text">
Throughout the videos, Rebecca demonstrates machine learning concepts mainly using the Wekinator software, however, in this guide we will provide resources that can allow for follow up work to be completed on the MIMIC platform using the Rapidlib machine learning library. Following each Session (~45 mins of videos, depending on how fast you make Rebecca speak), we will provide a set of tasks to help you explore and cement the concepts covered.
</p>
<p class = "tutorial-text">
  You can sign up for the course <a href = "https://www.kadenze.com/courses/machine-learning-for-musicians-and-artists/info" >here</a>. The course is free you do not require a certificate to finish or graded projects, and can be started at any time, and completed at any pace.
</p>
<h2 id="maxiaudio">Part 1: Introduction</h2>
<p class = "tutorial-text">
  To follow through with this we recommend first watching the <a href = "https://www.kadenze.com/courses/machine-learning-for-musicians-and-artists-v/sessions/introduction">Session 1: Introduction videos</a>
</p>
<p class = "tutorial-text">
  For this first part we are just going to get comfortable with using RapidLib to take an input, in this case the mouse, record alongside some output and then train a model.
</p>
<p class = "tutorial-text">
  <iframe class = "embedded-tutorial-code" src={{concat url "/code/8de3cbbe-b7c6-d79f-65fa-42fd1aa43a26?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 850px; overflow: hidden;">what?</iframe>
<a href = {{concat url "/code/8de3cbbe-b7c6-d79f-65fa-42fd1aa43a26"}}>Open Project</a>
</p>
<p class = "tutorial-text">
  Use the example below to randomise synth parameters until you find a sound you like. Move the square to somewhere on the screen, then click and hold to record samples. Then find more sounds and place them elsewhere on the screen and record again. When you have a few, hit "t" to train. Now when you move the mouse around you will be able to explore your newly trained sound space!
</p>
<p class = "tutorial-text">
  Try clearing the dataset ("x"), changing the training examples to see how this changes the behaviour of the system after it is re-trained. Spend some time experimenting with the trained models to start to understand how the models are changed.
</p>
<p class = "tutorial-text">
  ASIDE: You can complete this whole project largely using the embedded examples, however, if you want to take a closer look at the code you can check out how to use RapidLib <a href = "https://www.doc.gold.ac.uk/eavi/rapidmixapi.com/index.php/getting-started/">here</a>. It has an incredibly simple API.
</p>
<h2> Part 2: Classification, I </h2>
<p class = "tutorial-text">
  To follow through with this we recommend first watching the <a href = "https://www.kadenze.com/courses/machine-learning-for-musicians-and-artists-v/sessions/classification-part-i">Session 2: Classification, Part I videos </a>
</p>
<p class = "tutorial-text">
  Having given you a brief feel for how machine learning can allow you to map inputs, such as a mouse, to control an output, such as synthesis parameters, we will now examine how by incrementally building up our own datasets, we can sculpt the decision boundaries in classification tasks.
</p>
<p class = "tutorial-text">
  In the videos Rebecca used a program called the Classification Explorer. Below is a version of this to use on the MIMIC platform. In order to input training examples, hold down a number key (e.g. 1) and move the mouse (you may have to click inside the example first to bring it into focus). This will input examples of that class as long as you are holding down that number key. The decision boundary will then be displayed.
</p>
<p class = "tutorial-text">
  <iframe class = "embedded-tutorial-code" src={{concat url "/code/7f92bd4e-6d2b-181c-559f-4add766f2095?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 440px; overflow: hidden;">what?</iframe>
<a href = {{concat url "/code/7f92bd4e-6d2b-181c-559f-4add766f2095"}}>Open Project</a>
</p>
<p class = "tutorial-text">
  Try to choose a set of training examples that will draw the boundary on screen, with Class 1 on the left in red and Class 2 on the right in blue.
</p>
<img src = {{concat url "/images/decision1.png"}} style = "width:400px;height:400px;"/>
<p class = "tutorial-text">
  Keep improving your boundary by changing your training examples, re-training, and re-drawing the decision boundary until you are happy with how it looks. If you need to start again, just pause and play the example.
</p>
<p class = "tutorial-text">
  When actually making classifiers for a specific purpose, how close you need the decision boundary to match will depend on your intentions. We realise that it may not be possible or, or even desirable, for it to be perfect!
</p>
<p class = "tutorial-text">
  Now try to make this decision boundary, with Class 1 in red and Class 2 in blue.
</p>
<img src = {{concat url "/images/decision2.png"}} style = "width:400px;height:400px;"/>
<p class = "tutorial-text">
  ASIDE: If you want to use a different and output method than the mouse, feel free to fork the project and create your own dataset using RapidLib. Make sure you have two inputs and one output and your dataset has the structure [{input:[x1,x2], output:[y1]}]. Then retrain your model and run explorer.updateOutput() to see your new decision boundary.
</p>
<h2>Part 3: Regression</h2>
<p class = "tutorial-text">
  To follow through with this we recommend first watching the <a href = "https://www.kadenze.com/courses/machine-learning-for-musicians-and-artists-v/sessions/regression">Session 3: Regression videos</a>.
</p>
<p class = "tutorial-text">
In the videos Rebecca used a program called the Regression Explorer. Below is a version of this to use on the MIMIC platform. In order to input training examples, click onto screen at any point. The X value denotes the input value, whereas the y value denotes the output value. You will then see the regression line drawn as you add values. Try to get a feel for what types of lines are capable and how they’re influenced by the training data.
</p>
<p class = "tutorial-text">
  <iframe class = "embedded-tutorial-code" src={{concat url "/code/26ab5507-0d25-07eb-cb03-aaa93883765d?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 440px; overflow: hidden;">what?</iframe>
<a href = {{concat url "/code/26ab5507-0d25-07eb-cb03-aaa93883765d"}}>Open Project</a>
</p>
<p class = "tutorial-text">
Create a training dataset this way to produce the line below. Keep editing your data and/or algorithm until the regression line drawn by the Regression Explorer matches the one at right as closely as possible.
</p>
<img src = {{concat url "/images/decision3.png"}} style = "width:400px;height:400px;"/>
<p class = "tutorial-text">
Now, think about whether you might be able to create this same line using even fewer training examples. If you think it’s possible to create this line using fewer examples, delete your training dataset and give it a try!
</p>
<p class = "tutorial-text">
Now try to fit this more complicated regression line. Keep editing your training data until you have something that basically matches this shape. Once you have this, try completing with fewer examples.
</p>
<img src = {{concat url "/images/decision4.png"}} style = "width:400px;height:400px;"/>
<p class = "tutorial-text">
As with the Classification Explorer, feel free to fork the code use RapidLib yourself to use your own inputs and outputs. In this case you will need to have a dataset including one input and one output only.
</p>
<p class = "tutorial-text">
Now we are going to try and see if we can train a model with 3 outputs to behave consistently. Select an input (at least 1) from the examples below, and choose an output with EXACTLY 3 parameters. Below we have an example of using a slider as input to control a granular synthesiser (borrowed from <a href = "http://www.zya.cc/granular">Zya</a>) where the outputs of the regression model are the position in the soundfile, the release on the envelope of the grains and the density (how frequently a new grain is triggered).
</p>
<p class = "tutorial-text">
  <iframe class = "embedded-tutorial-code" src={{concat url "/code/5d67faaa-e4c3-771a-f824-fe5c5b978ab6?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 440px; overflow: hidden;">what?</iframe>
<a href = {{concat url "/code/5d67faaa-e4c3-771a-f824-fe5c5b978ab6"}}>Open Project</a>
</p>
<p class = "tutorial-text">
First, play around with the two parameters and click on different parts of the waveform, find some sounds you like. When you are ready to record, select the "Record" checkbox. From now on, whenever you play the synthesiser, your position in the sample, the release and density will be recorded, along with the input slider value. Record in some sounds you like, remembering to map each one to a different value on the input slider.
</p>
<p class = "tutorial-text">
When you are ready to play, select the "Run" checkbox. This will train your model with the recorded dataset and now all 3 synthesiser parameters will be controlled by just the one value from the input slider. Keep recording examples until you can reliably control the output.
</p>
<p class = "tutorial-text">
Next, train model to reliably access the following values. To clear your dataset, just pause and play the embedded code.
<ul>
<li>(0.0, 0.0, 0.0) (all models output 0 simultaneously)</li>
<li>(1.0, 1.0, 1.0) (all models output 1 simultaneously)</li>
<li>(0.5, 0.0, 1.0) (model 1 outputs 0.5, model 2 outputs 0, and model 3 outputs 1)</li>
</ul>
</p>
<h2>Part 4: Classification II</h2>
<p class = "tutorial-text">
  To follow through with this we recommend first watching the <a href = "https://www.kadenze.com/courses/machine-learning-for-musicians-and-artists-v/sessions/classification-part-ii">Session 4: Classification II videos</a>.
</p>
<p class = "tutorial-text">
  For this part we are going to revisit the Classification Explorer but this time we are going to experiment with more than 2 classes, as well as more complication decision boundaries.
</p>
<p class = "tutorial-text">
  <iframe class = "embedded-tutorial-code" src={{concat url "/code/7f92bd4e-6d2b-181c-559f-4add766f2095?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 440px; overflow: hidden;">what?</iframe>
<a href = {{concat url "/code/7f92bd4e-6d2b-181c-559f-4add766f2095"}}>Open Project</a>
</p>
<p class = "tutorial-text">
  By adding new training data, try to recreate the decision boundary below using the Classification Explorer. As you are doing this, think about
  <ul>
  <li>How the model improves (or not) as you add more examples.</li>
  <li>How well the shape of the decision boundary the algorithm seems to want to make matches the boundary you are trying to make.</li>
</ul>
</p>
<img src = {{concat url "/images/decision5.png"}} style = "width:400px;height:400px;"/>
<p class = "tutorial-text">
  Now restart the explorer and try to enter data that will give the decision boundary below. Think back to the videos, what is significant about this particular boundary, in comparison to others we have tried?
</p>
<img src = {{concat url "/images/decision6.png"}} style = "width:500px;height:400px;"/>
{{/if}}
{{#if isMaxim}}
<p class = "tutorial-text">
maximJS is an implementation of the Maximilian audio library in javascript using emscripten to compile code from C++ to javascript/asm.js. It allows powerful audio sequencing, synthesis and analysis all in the browser.
</p>
<p class = "tutorial-text">
First of all we're going to look at how to set up the audio context and load and play samples in a number of ways.
</p>
<h2 id="maxiaudio">Part 1: Samples</h2>
<h3 id="maxiaudio">maxiAudio</h3>
<p class = "tutorial-text">This the audio context. You must always have one to produce sound with maxiLib</p>
<h4 id="methods">methods</h4>
<h5 id="-init-">.init()</h5>
<p class = "tutorial-text">initialise the audio engine</p>
<h5 id="-outputisarray-isarray-numchannels-">.outputIsArray( isArray,  numChannels)</h5>
<p class = "tutorial-text">for multi channel  sound</p>
<ul>
<li>isArray = true or false</li>
<li>numChannels = 2, 4, or 8</li>
</ul>
<h5 id="-loadsample-sampleurl-maxisample-">.loadSample(sampleUrl, maxiSample)</h5>
<p class = "tutorial-text">load a sample from a maxiSample object</p>
<h4 id="properties">properties</h4>
<h5 id="-play">.play</h5>
<p class = "tutorial-text">the function which is the play loop</p>
<h5 id="-output">.output</h5>
<p class = "tutorial-text">the current value of the audio output</p>
<h4 id="example">example</h4>
<pre><code><span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> <span class="hljs-type">maximJs</span>.maxiAudio();
<span class="hljs-keyword">var</span> sample = <span class="hljs-keyword">new</span> <span class="hljs-type">maximJs</span>.maxiSample();

maxiAudio.init();
maxiAudio.loadSample(<span class="hljs-string">'cheese.wav'</span>, sample);
</code></pre><hr>
<h3 id="maxisample">maxiSample</h3>
<p class = "tutorial-text">Stores and plays an audio sample</p>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    <span class="hljs-keyword">var</span> sample1= <span class="hljs-keyword">new</span> maximJs.maxiSample();
    <span class="hljs-keyword">var</span> sample2= <span class="hljs-keyword">new</span> maximJs.maxiSample();
    <span class="hljs-keyword">var</span> clock = <span class="hljs-keyword">new</span> maximJs.maxiClock();
    <span class="hljs-keyword">var</span> beatCounter = <span class="hljs-number">0</span>;

    maxiAudio.init();
    maxiAudio.loadSample(<span class="hljs-string">"bassdrum13.wav"</span>, sample1);
    maxiAudio.loadSample(<span class="hljs-string">"hihat18.wav"</span>, sample2);
    clock.setTempo(<span class="hljs-number">87</span>);
    clock.setTicksPerBeat(<span class="hljs-number">8</span>);

    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">if</span> (sample1.isReady()) {
            clock.ticker();
            <span class="hljs-keyword">var</span> w=<span class="hljs-number">0</span>;
            <span class="hljs-keyword">if</span> (clock.isTick() ) {
                <span class="hljs-keyword">if</span> (beatCounter <span class="hljs-keyword">in</span> [<span class="hljs-number">0</span>,<span class="hljs-number">2</span>]) {
                    sample1.trigger();
                }
                <span class="hljs-keyword">if</span> (beatCounter <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>,<span class="hljs-number">5</span>,<span class="hljs-number">7</span>]) {
                    sample2.trigger();
                }
                beatCounter = (beatCounter+<span class="hljs-number">1</span>) % <span class="hljs-number">8</span>;
            }
            w = sample1.playOnce();
            w += sample2.playOnce();
            <span class="hljs-keyword">this</span>.output =  w;
        }
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h4 id="methods">methods</h4>
<h5 id="-play-">.play()</h5>
<p class = "tutorial-text">plays the sample at normal speed</p>
<h5 id="-play-playrate-">.play(playRate)</h5>
<p class = "tutorial-text">plays the sample at the specified play rate</p>
<h5 id="-playonce-">.playOnce()</h5>
<p class = "tutorial-text">plays the sample once at normal speed</p>
<h5 id="-playonce-playrate-">.playOnce(playRate)</h5>
<p class = "tutorial-text">plays the sample once at specified play rate</p>
<h5 id="-trigger-">.trigger()</h5>
<p class = "tutorial-text">set the playhead to zero (use in conjunction with playOnce)</p>
<h5 id="-isready-">.isReady()</h5>
<p class = "tutorial-text">returns true if sample is loaded</p>
<hr>
<h2 id="maxiaudio">Part 2: A Matter of Time and Space</h2>
<p class = "tutorial-text">
Now we can play load in samples and play them, we're going to look how to change their length and pitch independently.
</p>
<h3 id="maxitimestretch">maxiTimestretch</h3>
<p class = "tutorial-text">plays a sample at different rates leaving pitch unchanged</p>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    <span class="hljs-keyword">var</span> sample = <span class="hljs-keyword">new</span> maximJs.maxiSample();
    <span class="hljs-keyword">var</span> ts = <span class="hljs-keyword">new</span> maximJs.maxiTimestretch();
    <span class="hljs-keyword">var</span> ts2 = <span class="hljs-keyword">new</span> maximJs.maxiTimestretch();
    <span class="hljs-keyword">var</span> delay = <span class="hljs-keyword">new</span> maximJs.maxiDelayline();

    maxiAudio.init();

    <span class="hljs-comment">// you can add files into the document by going to Settings (gear icon) &gt; Files</span>
    <span class="hljs-comment">// uncomment this and change the file name to your sample</span>
    maxiAudio.loadSample(<span class="hljs-string">'45379__feedback__mono.wav'</span>, sample);
    ts.setSample(sample);
    ts2.setSample(sample);

    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">if</span>(sample.isReady()){
            <span class="hljs-keyword">var</span> w=<span class="hljs-number">0</span>;
            w = ts.play(<span class="hljs-number">0.5</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>) ;
            w = w +  ts2.play(<span class="hljs-number">0.1</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">0.2</span>);
            w = w  + delay.dl(w, <span class="hljs-number">200</span>, <span class="hljs-number">0.98</span>);
            <span class="hljs-keyword">this</span>.output =  w;
        }
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h4 id="methods">methods</h4>
<h5 id="-setsample-maxisample-">.setSample(maxiSample)</h5>
<p class = "tutorial-text">sets the sample play for timestretch to use</p>
<h5 id="-play-rate-grainlength-overlaps-startpos-">.play(rate, grainLength, overlaps, startPos)</h5>
<ul>
<li>rate (eg. 0.5 = half speed)</li>
<li>grainLength (a time in seconds)</li>
<li>overlaps (normally 2 is good)</li>
<li>startPos (where to start playing in the sample - in seconds)</li>
</ul>
<h5 id="-setposition-startpos-">.setPosition(startPos)</h5>
<p class = "tutorial-text">useful for resetting a sound</p>
<h5 id="-getposition-">.getPosition()</h5>
<p class = "tutorial-text">returns position in ???</p>
<h5 id="-getnormalisedposition-">.getNormalisedPosition()</h5>
<p class = "tutorial-text">Useful for ending sample play back</p>
<p class = "tutorial-text"><br><br></p>
<h3 id="maxipitchshift">maxiPitchShift</h3>
<p class = "tutorial-text">plays a sample at different pitches leaving the speed unchanged</p>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    <span class="hljs-keyword">var</span> sample = <span class="hljs-keyword">new</span> maximJs.maxiSample();
    <span class="hljs-keyword">var</span> ts = <span class="hljs-keyword">new</span> maximJs.maxiPitchShift();
    <span class="hljs-keyword">var</span> ts2 = <span class="hljs-keyword">new</span> maximJs.maxiPitchShift();
    <span class="hljs-keyword">var</span> delay = <span class="hljs-keyword">new</span> maximJs.maxiDelayline();

    maxiAudio.init();

    <span class="hljs-comment">// you can add files into the document by going to Settings (gear icon) &gt; Files</span>
    <span class="hljs-comment">// uncomment this and change the file name to your sample</span>
    maxiAudio.loadSample(<span class="hljs-string">'45379__feedback__mono.wav'</span>, sample);
    ts.setSample(sample);
    ts2.setSample(sample);

    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">if</span>(sample.isReady()){
            <span class="hljs-keyword">var</span> w=<span class="hljs-number">0</span>;
            w = ts.play(<span class="hljs-number">0.5</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>) ;
            w = w +  ts2.play(<span class="hljs-number">0.1</span>,<span class="hljs-number">0.1</span>,<span class="hljs-number">4</span>,<span class="hljs-number">0.2</span>);
            w = w  + delay.dl(w, <span class="hljs-number">200</span>, <span class="hljs-number">0.98</span>);
            <span class="hljs-keyword">this</span>.output =  w;
        }
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h4 id="methods">methods</h4>
<h5 id="-setsample-maxisample-">.setSample(maxiSample)</h5>
<p class = "tutorial-text">sets the sample play for pitchShift to use</p>
<h5 id="-play-pitch-grainlength-overlaps-startpos-">.play(pitch, grainLength, overlaps, startPos)</h5>
<ul>
<li>pitch (eg. 0.5 = half pitch)</li>
<li>grainLength (a time in seconds)</li>
<li>overlaps (normally 2 is good)</li>
<li>startPos (where to start playing in the sample - in seconds)</li>
</ul>
<h5 id="-setposition-startpos-">.setPosition(startPos)</h5>
<p class = "tutorial-text">useful for resetting a sound</p>
<h5 id="-getposition-">.getPosition()</h5>
<p class = "tutorial-text">returns position in ???</p>
<h5 id="-getnormalisedposition-">.getNormalisedPosition()</h5>
<p class = "tutorial-text">Useful for ending sample play back</p>
<hr>
<h3 id="maxipitchstretch">maxiPitchStretch</h3>
<p class = "tutorial-text">plays a sample with independent control of pitch and speed</p>
<h4 id="methods">methods</h4>
<h5 id="-setsample-maxisample-">.setSample(maxiSample)</h5>
<p class = "tutorial-text">sets the sample play for timestretch to use</p>
<h5 id="-play-pitch-rate-grainlength-overlaps-startpos-">.play(pitch, rate, grainLength, overlaps, startPos)</h5>
<ul>
<li>pitch (eg. 0.5 = half pitch)</li>
<li>rate (eg. 0.5 = half speed)</li>
<li>grainLength (a time in seconds)</li>
<li>overlaps (normally 2 is good)</li>
<li>startPos (where to start playing in the sample - in seconds)</li>
</ul>
<h5 id="-getposition-">.getPosition()</h5>
<p class = "tutorial-text">returns position in ???</p>
<h5 id="-getnormalisedposition-">.getNormalisedPosition()</h5>
<p class = "tutorial-text">Useful for ending sample play back</p>
<h5 id="-setposition-startpos-">.setPosition(startPos)</h5>
<p class = "tutorial-text">useful for resetting a sound</p>
<hr>
<h3 id="maxidelayline">maxiDelayline</h3>
<p class = "tutorial-text">A simple delay line</p>
<h4 id="methods">methods</h4>
<h5 id="-dl-inputsignal-delaytime-foldback-">.dl(inputSignal, delayTime, foldback)</h5>
<p class = "tutorial-text">process a signal with delay</p>
<ul>
<li>inputSignal (any signal eg. output from an oscillator)</li>
<li>delayTime (a value in milliseconds, max 2000)</li>
<li>foldback (how much of the signal to feedback into the delay buffer - determines how long echoes last), between 0 and 1</li>
</ul>
<hr>
<h2>Part 3: Synthesis</h2>
<p class = "tutorial-text">
  As well as augmented samples, maximJS can also be used to create new sounds. Here we cover the essential sound synthesis methods.
</p>
<h3 id="maxiosc">maxiOsc</h3>
<p class = "tutorial-text">An oscillator with methods for a number of waveforms</p>
<h4 id="methods">methods</h4>
<h5 id="-sinewave-frequency-">.sinewave(frequency)</h5>
<p class = "tutorial-text">outputs a sine wave at the given frequency between -1.0 &amp; 1.0</p>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    maxiAudio.init();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">this</span>.output = myWave.sinewave(<span class="hljs-number">100</span>);
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h5 id="-coswave-frequency-">.coswave(frequency)</h5>
<p class = "tutorial-text">outputs a cosine wave at the given frequency between -1.0 &amp; 1.0</p>
<h5 id="-triangle-frequency-">.triangle(frequency)</h5>
<p class = "tutorial-text">outputs a triangle wave at the given frequency between -1.0 &amp; 1.0</p>
<h5 id="-saw-frequency-">.saw(frequency)</h5>
<p class = "tutorial-text">outputs a sawtooth wave at the given frequency between -1.0 &amp; 1.0</p>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    maxiAudio.init();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">this</span>.output = myWave.saw(<span class="hljs-number">100</span>);
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h5 id="-sawn-frequency-">.sawn(frequency)</h5>
<p class = "tutorial-text">outputs a band-limited sawtooth wave at the given frequency between -1.0 &amp; 1.0</p>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    maxiAudio.init();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">this</span>.output = myWave.sawn(<span class="hljs-number">100</span>);
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h5 id="-square-frequency-">.square(frequency)</h5>
<p class = "tutorial-text">outputs a square wave at the given frequency between -1.0 &amp; 1.0</p>
<h5 id="-pulse-frequency-pulsewidth-">.pulse(frequency, pulsewidth)</h5>
<p class = "tutorial-text">outputs a square wave at the given frequency and pulsewidth between -1.0 &amp; 1.0</p>
<ul>
<li>pulsewidth in the range 0 to 1</li>
</ul>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    maxiAudio.init();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">this</span>.output = myWave.pulse(<span class="hljs-number">100</span>, <span class="hljs-number">0.4</span>);
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h5 id="-phasor-frequency-">.phasor(frequency)</h5>
<p class = "tutorial-text">outputs a linear ramp at the given frequency between 0.0 &amp; 1.0</p>
<h5 id="-phasor-frequency-startphase-endphase-">.phasor(frequency, startPhase, endPhase)</h5>
<p class = "tutorial-text">outputs a linear ramp at the given frequency between 0.0 &amp; 1.0</p>
<ul>
<li>startPhase and endPhase are the start and end values of the ramp, between 0.0 &amp; 1.0</li>
</ul>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">
    <span class="hljs-comment">//alarm sound</span>
    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    maxiAudio.init();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myWave2 = <span class="hljs-keyword">new</span> maximJs.maxiOsc();

    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">this</span>.output = myWave.saw(<span class="hljs-number">200</span> + (myWave2.phasor(<span class="hljs-number">2</span>,<span class="hljs-number">0.2</span>,<span class="hljs-number">0.9</span>) * <span class="hljs-number">500</span>));
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h5 id="-noise-">.noise()</h5>
<p class = "tutorial-text">white noise</p>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">
    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    maxiAudio.init();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();

    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">this</span>.output = myWave.noise();
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h5 id="-phasereset-phase-">.phaseReset(phase)</h5>
<p class = "tutorial-text">reset the phase to a specific value</p>
<ul>
<li>phase (a value between 0 &amp; 1)</li>
</ul>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">
    <span class="hljs-comment">//this will create silence by combining two out of phase sines</span>
    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    maxiAudio.init();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myWave2 = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    myWave2.phaseReset(<span class="hljs-number">0.5</span>);
    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">this</span>.output = myWave.sinewave(<span class="hljs-number">100</span>) + myWave2.sinewave(<span class="hljs-number">100</span>);
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><hr>
<h2>Part 4: Envelopes and Filters</h2>
<p class = "tutorial-text">
  Once we've made some generators, we can start to shape the sound using filters and envelopes.
</p>
<h3 id="maxienv">maxiEnv</h3>
<p class = "tutorial-text">An adsr envelope.</p>
<h4 id="methods">methods</h4>
<h5 id="-setattack-time-">.setAttack(time)</h5>
<ul>
<li>time = milliseconds</li>
</ul>
<h5 id="-setdecay-time-">.setDecay(time)</h5>
<ul>
<li>time = milliseconds</li>
</ul>
<h5 id="-setsustain-level-">.setSustain(level)</h5>
<ul>
<li>level = a value between 0.0 and 1.0</li>
</ul>
<h5 id="-setrelease-time-">.setRelease(time)</h5>
<ul>
<li>time = milliseconds</li>
</ul>
<h5 id="-adsr-level-trigger-">.adsr(level, trigger)</h5>
<ul>
<li>level (the overall level of the envelope; everything will be scaled by this value)</li>
<li>trigger (envelope will begin attack when set to 1.0 and release when set to 0.0)</li>
</ul>
<hr>
<h3 id="maxifilter">maxiFilter</h3>
<p class = "tutorial-text">A bunch of useful filter methods</p>
<h4 id="methods">methods</h4>
<h5 id="-lores-input-cutoff-resonance-">.lores(input, cutoff, resonance)</h5>
<p class = "tutorial-text">A lowpass resonant filter. Returns the filtered frequency.</p>
<ul>
<li>input =  input signal</li>
<li>cutoff = cutoff frequency in Hz</li>
<li>resonance = a value between 0.0 &amp; 10.0</li>
</ul>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myLFO = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myFilter = <span class="hljs-keyword">new</span> maximJs.maxiFilter();

    maxiAudio.init();


    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">var</span> w=<span class="hljs-number">0</span>;
        w = myWave.saw(<span class="hljs-number">100</span>);
        w = myFilter.lores(w, <span class="hljs-number">1000</span> + (myLFO.sinewave(<span class="hljs-number">1</span>) * <span class="hljs-number">800</span>), <span class="hljs-number">3</span>);
        <span class="hljs-keyword">this</span>.output =  w;
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h5 id="-hires-input-cutoff-resonance-">.hires(input, cutoff, resonance)</h5>
<p class = "tutorial-text">A highpass resonant filter. Returns the filtered frequency.</p>
<ul>
<li>input =  input signal</li>
<li>cutoff = cutoff frequency in Hz</li>
<li>resonance = a value between 0.0 &amp; 10.0</li>
</ul>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myLFO = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myFilter = <span class="hljs-keyword">new</span> maximJs.maxiFilter();

    maxiAudio.init();


    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">var</span> w=<span class="hljs-number">0</span>;
        w = myWave.saw(<span class="hljs-number">100</span>);
        w = myFilter.hires(w, <span class="hljs-number">1000</span> + (myLFO.sinewave(<span class="hljs-number">1</span>) * <span class="hljs-number">800</span>), <span class="hljs-number">3</span>);
        <span class="hljs-keyword">this</span>.output =  w;
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h5 id="-lopass-input-cutoff-">.lopass(input, cutoff)</h5>
<p class = "tutorial-text">A one-pole low-pass filter, cutoff between 0 and 1</p>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myLFO = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myFilter = <span class="hljs-keyword">new</span> maximJs.maxiFilter();

    maxiAudio.init();


    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">var</span> w=<span class="hljs-number">0</span>;
        w = myWave.saw(<span class="hljs-number">100</span>);
        w = myFilter.lopass(w, <span class="hljs-number">0.25</span> + (myLFO.sinewave(<span class="hljs-number">1</span>) * <span class="hljs-number">0.25</span>));
        <span class="hljs-keyword">this</span>.output =  w;
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h5 id="-hipass-input-cutoff-">.hipass(input, cutoff)</h5>
<p class = "tutorial-text">A one-pole high-pass filter, cutoff between 0 and 1</p>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myLFO = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myFilter = <span class="hljs-keyword">new</span> maximJs.maxiFilter();

    maxiAudio.init();


    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">var</span> w=<span class="hljs-number">0</span>;
        w = myWave.saw(<span class="hljs-number">100</span>);
        w = myFilter.hipass(w, <span class="hljs-number">0.5</span> + (myLFO.sinewave(<span class="hljs-number">1</span>) * <span class="hljs-number">0.25</span>));
        <span class="hljs-keyword">this</span>.output =  w;
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><hr>
<h3 id="maxisvf">maxiSVF</h3>
<p class = "tutorial-text">A state variable filter, see <a href="http://www.cytomic.com/files/dsp/SvfLinearTrapOptimised.pdf">http://www.cytomic.com/files/dsp/SvfLinearTrapOptimised.pdf</a></p>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    <span class="hljs-keyword">var</span> myWave = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myLFO = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> myLFO2 = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> mySVF = <span class="hljs-keyword">new</span> maximJs.maxiSVF();

    maxiAudio.init();

    mySVF.setCutoff(<span class="hljs-number">200</span>);
    mySVF.setResonance(<span class="hljs-number">4</span>);

    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">var</span> w=<span class="hljs-number">0</span>;
        mySVF.setCutoff(<span class="hljs-number">2000</span> + (myLFO.sinewave(<span class="hljs-number">1</span>) * <span class="hljs-number">1800</span>));
        mySVF.setResonance(<span class="hljs-number">7</span> + (myLFO.coswave(<span class="hljs-number">0.1</span>) * <span class="hljs-number">6</span>));
        w = myWave.saw(<span class="hljs-number">100</span>);
        w = mySVF.play(w, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>, <span class="hljs-number">0.0</span>);
        <span class="hljs-keyword">this</span>.output =  w;
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><h4 id="methods">methods</h4>
<h5 id="-play-input-lowpassmix-highpassmix-bandpassmix-notchmix-">.play(input, lowPassMix, highPassMix, bandPassMix, notchMix)</h5>
<ul>
<li>input: a signal</li>
<li>lowPassMix:  the amount of low pass filtering, between 0 and 1</li>
<li>highPassMix:  the amount of high pass filtering, between 0 and 1</li>
<li>bandPassMix:  the amount of band pass filtering, between 0 and 1</li>
<li>notchMix:  the amount of notch filtering, between 0 and 1</li>
</ul>
<h5 id="-setcutoff-frequency-">.setCutoff(frequency)</h5>
<p class = "tutorial-text">frequency between 20 and 20000, although this filter sounds best below 5000</p>
<h5 id="-setresonance-amount-">.setResonance(amount)</h5>
<p class = "tutorial-text">from 0 upwards, starts to ring from 2-3ish, cracks a bit around 10</p>
<hr>
<h3 id="maxiflanger">maxiFlanger</h3>
<h4 id="methods">methods</h4>
<h5 id="-flange-input-delay-feedback-speed-depth-">.flange(input, delay, feedback, speed, depth)</h5>
<ul>
<li>input: an input signal</li>
<li>delay: delay time, in ms, max 2000</li>
<li>feedback: between 0 and 1</li>
<li>speed: lfo speed in Hz</li>
<li>depth: between 0 and 1</li>
</ul>
<pre><code><span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="actionscript">

    <span class="hljs-keyword">var</span> maxiAudio = <span class="hljs-keyword">new</span> maximJs.maxiAudio();
    <span class="hljs-keyword">var</span> osc = <span class="hljs-keyword">new</span> maximJs.maxiOsc();
    <span class="hljs-keyword">var</span> flanger = <span class="hljs-keyword">new</span> maximJs.maxiFlanger();
    maxiAudio.init();

    maxiAudio.play = <span class="hljs-function"><span class="hljs-keyword">function</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">var</span> w = <span class="hljs-number">0</span>;
        w = osc.pulse(<span class="hljs-number">40</span>,<span class="hljs-number">0.1</span>);
        w = flanger.flange(w, <span class="hljs-number">100</span>, <span class="hljs-number">0.8</span>, <span class="hljs-number">0.2</span>, <span class="hljs-number">0.8</span>);
        <span class="hljs-keyword">this</span>.output = w;
    };

</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
</code></pre><hr>
<h2>Part 5: Spectral Analysis</h2>
<p class = "tutorial-text">
  maximJS can also be used to analyse and edit sound in the frequency domain
</p>
<h3 id="maxifft">maxiFFT</h3>
<h4 id="methods">methods</h4>
<h5 id="-setup-fftsize-windowsize-hopsize-">.setup(fftSize, windowSize, hopSize)</h5>
<p class = "tutorial-text">must be called before using the FFT</p>
<ul>
<li>fftSize = (A power of two, 1024, 512 .. etc)</li>
<li>windowSize = half the fftSize</li>
<li>hopSize = half the windowSize</li>
</ul>
<h5 id="-process-sig-">.process(sig)</h5>
<p class = "tutorial-text">returns true if successful</p>
<ul>
<li>sig = signal in</li>
</ul>
<h5 id="-getmagnitude-index-">.getMagnitude(index)</h5>
<p class = "tutorial-text">get the magnitude of a particular bin</p>
<ul>
<li>index = A number between 0 and the fftSize/2</li>
</ul>
<h5 id="-getmagnitudedb-index-">.getMagnitudeDB(index)</h5>
<p class = "tutorial-text">get the decibels of a particular bin</p>
<h5 id="-magstodb-">.magsToDb()</h5>
<p class = "tutorial-text">perform the conversion on all bins</p>
<hr>
<h3 id="convert">convert</h3>
<p class = "tutorial-text">A collection of conversion functions. Currently numbering one !</p>
<h4 id="methods">methods</h4>
<h5 id="-mtof-midi-">.mtof(midi)</h5>
<p class = "tutorial-text">pass a midi value and its frequency is returned</p>
<hr>
<h3 id="maximix">maxiMix</h3>
<p class = "tutorial-text">A multichannel mixer.</p>
<h4 id="methods">methods</h4>
<h5 id="-stereo-sig-outputarray-pan-">.stereo(sig, outputArray, pan)</h5>
<p class = "tutorial-text">Makes a stereo mix.</p>
<ul>
<li>sig = inputsignal</li>
<li>outputArray = VectorDbl array (see maxiTools)</li>
<li>pan = a value between 0 &amp; 1</li>
</ul>
<hr>
<h3 id="maxitools">maxiTools</h3>
<h4 id="methods">methods</h4>
<h5 id="-getarrayasvectordbl-inputarray-">.getArrayAsVectorDbl(inputArray)</h5>
<p class = "tutorial-text">Returns the array as a VectorDbl object.  (Needed for maxiMix).</p>
<h3 id="undocumented-classes">Undocumented classes</h3>
<ul>
<li>maxiArray</li>
<li>maxiChorus</li>
<li>maxiClock</li>
<li>maxiDCBlocker</li>
<li>maxiDistortion</li>
<li>maxiDyn</li>
<li>maxiEnvelope</li>
<li><p class = "tutorial-text">maxiEnvelopeFollower (undefined)</p>
</li>
<li><p class = "tutorial-text">maxiFFTOctaveAnalyzer</p>
</li>
<li>maxiHats</li>
<li>maxiIFFT</li>
<li>maxiKick</li>
<li>maxiLagExp</li>
<li>maxiMFCC</li>
<li><p class = "tutorial-text">maxiMap</p>
</li>
<li><p class = "tutorial-text">maxiSettings</p>
</li>
<li>maxiSnare</li>
<li>maxiTools</li>
</ul>

{{/if}}
{{#if isMMLL}}
<h2>Part 1: Musical Machine Listening</h2>
<p class = "tutorial-text">
Machine listening is the attempt to make computers hear sound intelligently. We often emulate the human hearing system, though engineering may not mirror human anatomy, and may deviate from physiological function, including purely mathematical algorithms to extract some sort of further information from audio signals. The interest of the MIMIC project is in musical machine listening, that is, the computer understanding of musical audio signals, and the Musical Machine Listening Library introduced here (subsequently MMLL) is a javascript library to do just that, in the web browser.
</p>

<p class = "tutorial-text">
The library provides a variety of higher level musical listening facilities for computer music, such as onset detection, chord detection, beat tracking and auditory modelling. All the listening objects can run live, to benefit the creation of interative music systems and live electronic music compositions. They can also render audio faster than realtime if called outside of a live processing callback, suitable for the analysis of audio files for machine learning purposes. The library also includes analysis and resynthesis capability from the inverse Fourier transform and via the tracking phase vocoder (which identifies sinusoidal partial trails within audio signals).
</p>

<h2>Part 2: Feature Extracting</h2>
<p class = "tutorial-text">
The first embeded example here is a feature extractor from live audio. You can choose as input either a sound file from your hard drive, or an attached microphone. Note that you will need to give permission for the microphone to run within a web browser, for security reasons. A single feature is extracted, the Sensory Dissonance (how rough sounding tha audio is, according to a perceptual model). If you selected an audio file, it will play back, but if you selected microphone the output audio will be silent to avoid feedback.
</p>

<iframe class = "embedded-tutorial-code" src={{concat url "/code/f6a258e2-35c4-6b08-0bbf-07f334de613a?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 300px; overflow: hidden;">what?</iframe>
<p class = "tutorial-text">
<a href = {{concat url "/code/f6a258e2-35c4-6b08-0bbf-07f334de613a"}}>Open Project</a>
</p>
<p class = "tutorial-text">
The second embeded example is a live spectral view, showing the results of a Fast Fourier Transform of successive snapshots of the input signal. The power spectrum and phase spectrum are both plotted, in linear frequency range. Most of the activity will tend to be on the left of the plot of the power spectrum, for normal audio sources, whose spectral content tends to drop off for higher frequencies. You can choose the gain for the output to hear or not hear the source signal (the default is silence).
</p>

<p class = "tutorial-text"><iframe class = "embedded-tutorial-code" src={{concat url "/code/38c2887a-f8f3-5959-324c-7c0f176c0db7?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height:350px; overflow: hidden;">what?</iframe></p>
<p class = "tutorial-text">
<a href = {{concat url "/code/38c2887a-f8f3-5959-324c-7c0f176c0db7"}}>Open Project</a>
</p>
<p class = "tutorial-text">
The third embeded example is an onset detector, which reacts to percussive events in the input signal. If you are using live microphone near a speaker you may find headphones work best, to avoid feedback effects. An onset is indicated by a flashing colour change; changing the threshold adjusts the sensitivity of detection.
</p>

<p class = "tutorial-text"><iframe class = "embedded-tutorial-code" src={{concat url "/code/fcdf62d8-a47b-1ddf-f16a-9cd09b328a65?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 350px; overflow: hidden;">what?</iframe></p>
<p class = "tutorial-text">
<a href = {{concat url "/code/fcdf62d8-a47b-1ddf-f16a-9cd09b328a65"}}>Open Project</a>
</p>
<h2>Part 3: Making Music</h2>
<p class = "tutorial-text">
Once an input sound is analysed, you can synthesize output based on the features, work with machine learning to further classify or process inputs based on the features,and make generally responsive and interactive music systems for concerts, installations, websites, etc
</p>

<p class = "tutorial-text">Some more developed examples available on codecircle are linked now.</p>

<p class = "tutorial-text">Spectral delay based on spectral resynthesis. The input is analysed by FFT, then particular spectral bins can be independently delayed and fed back on themselves to make a diffuse delayed filterbank.</p>

<iframe class = "embedded-tutorial-code" src={{concat url "/code/d5499af6-f4f3-2683-0c05-b700f1a9f1b1?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 650px; overflow: hidden;">what?</iframe>
<p class = "tutorial-text">
<a href = {{concat url "/code/d5499af6-f4f3-2683-0c05-b700f1a9f1b1"}}>Open Project</a>
</p>
<p class = "tutorial-text">bbcut, based on beat tracking. The input is cut up live into stuttering buffers, with the cut points determined by tracking of the primary metrical level in the music.</p>

<p class = "tutorial-text"><iframe class = "embedded-tutorial-code" src={{concat url "/code/5ed346fe-f7d5-b7ce-87a4-df6e352dbb4a?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 550px;  overflow: hidden;">what?</iframe></p>
<p class = "tutorial-text">
<a href = {{concat url "/code/5ed346fe-f7d5-b7ce-87a4-df6e352dbb4a"}}>Open Project</a>
</p>
<h2>Part 4: Getting Started With Code</h2>
<p class = "tutorial-text">The library can be used just for the machine listening objects, used within your own audio callback (e.g., as part of a ScriptProcessorNode), or via a quick set-up frontend that hides Web Audio API details and  has you write setup and audio callback functions analogous to Processing's setup and draw.</p>

<p class = "tutorial-text">The latter method is the one explained here, but expert Web Audio API people should find it easy enough to just take the analyzers for their own work. Only including the precompiled MMLL.js file is needed to deploy the library, though from the home directory of the library you can compile it afresh via the shell script provided (it is just a concatenation of the js source files).</p>

<p class = "tutorial-text">The typical expectation of a machine listening object is that we are working at 44.1KHz sampling rate and that a mono (single channel) input block of samples will be provided for analysis. The objects deal with accumulating samples ready for processing (often via an FFT) themselves and the user doesn't have to worry about that part. However, objects should cope at other standard sampling rates such as 48KHz, 88.2KHz and 96 KHz, even if performance is sub-optimal (for example, the onset detector was developed based on evaluation over a corpus of 44.1KHz samples, so works best at this home rate).</p>

<p class = "tutorial-text">
  A minimal code example is reproduced below. Note how the machine listener object is prefixed with MMLL, and the SetUp function is passed the sampling rate, needed for initialising the listener. The CallBack is where the main action happens, as each new block of input samples is passed in. The input and output arguments hold MMLLInput and MMLLOutpu objects, which make the channels of input and output audio accessible, as well as a special input.monoinput which is a single channel ready for the listener. If a stereo sound file is loaded or two channel live input requested, the monoinput will be the average of the left and right channels. The output object assumes a stereo output for now, exposing the left and right channel data arrays.</p>
<pre>
  <code>
var audioblocksize = 256; //lowest latency possible

var setup = function SetUp(sampleRate) {
  sensorydissonance = new MMLLSensoryDissonance(sampleRate);
};

var callback = function CallBack(input,output,n) {

  var dissonance = sensorydissonance.next(input.monoinput);

  console.log(dissonance);

  for (i = 0; i &lt; n; ++i) {
      output.outputL[i] = input.inputL[i];
      output.outputR[i] = input.inputR[i];
  }

};

var gui = new MMLLBasicGUISetup(callback,setup,audioblocksize,true,true);
</code>
</pre>
<p class = "tutorial-text">
  MMLL was developed by <a href="http://composerprogrammer.com/index.html">Nick Collins</a> as part of the AHRC funded MIMIC project (Musically Intelligent Machines Interacting Creatively). MMLL is released under an MIT license, see the included COPYING.txt file. The source code is available at <a href="https://github.com/sicklincoln/MMLL">github</a> though you can use it straight away from a web page just by linking to the <a href="https://raw.githubusercontent.com/sicklincoln/MMLL/master/MMLL.js">MMLL.js</a> source code file. The Examples folder provides a test example for each listener currently available in the library.</p>
{{/if}}
{{#if isEvolib}}

<p class = "tutorial-text">
How about using a machine intelligence technique to help us to program a modular synthesizer? In this guide, we'll show you how.
</p>
<h2>
Introduction
</h2>
<p class = "tutorial-text">
A lot of recent machine learning systems that you may have read about use things called deep neural networks to do creative things like writing music, generating images and so on. But there are many other techniques used to allow computers to do seemingly smart things. One of these is called a genetic algorithm. With genetic algorithms, we can actually breed things inside a computer, just like we might breed new varieties of crops or animals. The idea is to work with a small population of things (in this case, sounds) which we are going breed and mutate until we are satisfied with the results.
</p>
<p class = "tutorial-text">
In this example, we are going to use a genetic algorithm to breed virtual modular synthesizer patches. We have created a simple Javascript library for you called Evolib that makes this possible.
</p>
<h2>
Part 1: getting started - make a sound
</h2>
<p class = "tutorial-text">
Let's get started by creating a random synthesizer patch, then we'll find out how to improve it through selective breeding.
</p>
<p class = "tutorial-text">
Here is some starter code which just pulls in the evolib library. You'll need to upload evolib.js as a file asset:
</p>
<pre>
<code>
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;script src="evolib.js"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;/body&gt;
&lt;/html&gt;
</code>
</pre>
<p class = "tutorial-text">
Now we are ready to tell evolib to make some sounds. Put this code in the body tag somewhere - this creates a new population of 5 sounds, each sound has 30 modules. The modules might be oscillators or filters, and can be wired to eachother in different ways. The modules and wiring starts off totally random.
</p>
<pre>
  <code>
&lt;script language="javascript" type="text/javascript"&gt;
Evolib.newPopulation(5, 30); // 5 sounds, 30 modules each
&lt;/script&gt;
</code>
</pre>
<p class = "tutorial-text">
Now we want to listen to our sounds.
</p>
<p class = "tutorial-text">
Web browsers don't let us play any sound unless the user has clicked on something first. To listen to one of the sounds then, we need to add a button and tell it what to do when they click it.
</p>
<p class = "tutorial-text">
Add this to the body tag:

<pre>
  <code>
&lt;button onclick="Evolib.play(0)"&gt;Listen to sound 0&lt;/button&gt;
</code>
</pre>
<p class = "tutorial-text">
Now how about another button to stop the sound?
</p>

<pre>
  <code>
&lt;button onclick="Evolib.stop(0)"&gt;Stop the sound&lt;/button&gt;
</code>
</pre>
<p class = "tutorial-text">
Sometimes, the sounds are silent. Imagine if you randomly wired up 30 randomly selected oscillators and filters - would it always make a sound? Let's add another button that let's us generate a new random sound easily so we can keep pressing it until we get a decent sound.
</p>
<pre>
  <code>
&lt;button onclick="Evolib.newPopulation(5, 30);  Evolib.play(0)"&gt;new sound&lt;/button&gt;
</code>
</pre>
<p class = "tutorial-text">
Note that this button generates a new population, then plays the first sound.
</p>
<p class = "tutorial-text">
Here is the complete code so far
</p>
<p class = "tutorial-text">
  <iframe class = "embedded-tutorial-code" src={{concat url "/code/a990f234-5769-c556-b49a-0154204a016a?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 350px; overflow: hidden;">what?</iframe>
<a href = {{concat url "/code/a990f234-5769-c556-b49a-0154204a016a"}}>Open Project</a>
</p>
<h2>
Part 2: mutate the sound
</h2>
<p class = "tutorial-text">
Now we have some neat sounds, we are going to start using evolutionary computation to mutate them. Let's get straight to mutating sounds, then we'll think about what is going on.
</p>
<p class = "tutorial-text">
Add this to your set of buttons:
</p>
<pre>
  <code>
  &lt;button
   onclick="Evolib.evolve([0], 0.1);Evolib.play(0)"&gt;
     mutate
  &lt;/button&gt;
</code>
</pre>
Try clicking the new sound button until you get a decent sound. Then click on mutate repeatedly, and you should hear the sound changing slightly. This is the sound being mutated.

The important code here is the call to Evolib.evolve:
<pre>
  <code>
Evolib.evolve([0], 0.1);
</code>
</pre>
</p>
<p class = "tutorial-text">
It takes two arguments - the first is a list of numbers (in this case, just 0) which are the sounds we want to 'evolve'. The second is the mutation rate. The higher the mutation rate, the more the sound will change each time you mutate it.
</p>
<p class = "tutorial-text">
The power of genetic algorithms lies in the fact that they represent the things you are evolving in a form that can be mutated, and even crossed with other things. This is very similar to how plants and animals are described in their DNA and changing the DNA changes the plant or the animal.
</p>
<p class = "tutorial-text">
The DNA of an evolib sound is a list of numbers, like this: 0.5, 0.125, 0.255 etc. One number might say what kind of module it is (&lt; 0.5? its a filter. &gt;= 0.5? its an oscillator). Another number might set up the initial state of the module, e.g. the filter cutoff frequency (0-5000Hz). Other numbers describe how that module should be wired to other modules, by specifying a connection range.
</p>
<p class = "tutorial-text">
Here is the complete code:
</p>
<p class = "tutorial-text">
  <iframe class = "embedded-tutorial-code" src={{concat url "/code/3afdc780-e5f8-3ff1-0e31-eb76859c6703?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 350px; overflow: hidden;">what?</iframe>
<a href = {{concat url "/code/3afdc780-e5f8-3ff1-0e31-eb76859c6703"}}>Open Project</a>
</p>
<h2>
Part 3: selecting sounds for breeding
</h2>
<p class = "tutorial-text">
So far, we have only been working with a single sound and mutating it. Now we are going to get access to a population of sounds, so we can choose which mutant we want to breed from.
</p>
<p class = "tutorial-text">
Try adding some more play buttons to the program, so your play buttons look like this:
</p>
<pre>
  <code>
  &lt;button onclick="Evolib.play(0)"br&gt;play 1&lt;/buttonbr&gt;
&lt;br&gt;
  &lt;button onclick="Evolib.play(1)"br&gt;play 1&lt;/buttonbr&gt;
&lt;brbr&gt;
  &lt;button onclick="Evolib.play(2)"br&gt;play 1&lt;/buttonbr&gt;
&lt;brbr&gt;
  &lt;button onclick="Evolib.play(3)"br&gt;play 2&lt;/buttonbr&gt;
&lt;brbr&gt;
  &lt;button onclick="Evolib.play(4)"br&gt;play 3&lt;/buttonbr&gt;
</code>
</pre>
<p class = "tutorial-text">
Now you can listen to all 5 sounds in the population. Try clicking the buttons. You will hear that they all sound different. That is because they are all random sounds.
</p>
<p class = "tutorial-text">
Now let's add buttons which allow us to choose which sound we want to create the next population from, for example this one selects sound 1 for mutation:
</p>
<pre>
  <code>
  &lt;button onclick="Evolib.play(1)"br&gt;play 1&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.evolve([1], 0.1);Evolib.play(0)"br&gt;mutate&lt;/buttonbr&gt;
</code>
</pre>
<p class = "tutorial-text">
You'll end up with something like this, which shows the full set of buttons:
</p>
<pre>
  <code>
  &lt;button onclick="Evolib.play(0)"br&gt;play 0&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.evolve([0], 0.1);Evolib.play(0)"&gt;mutate&lt;/buttonbr&gt;
  &lt;brbr&gt;
  &lt;button onclick="Evolib.play(1)"&gt;play 1&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.evolve([1], 0.1);Evolib.play(0)"&gt;mutate&lt;/buttonbr&gt;
  &lt;brbr&gt;
  &lt;button onclick="Evolib.play(2)"&gt;play 2&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.evolve([2], 0.1);Evolib.play(0)"&gt;mutate&lt;/buttonbr&gt;
  &lt;brbr&gt;
  &lt;button onclick="Evolib.play(3)"&gt;play 3&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.evolve([3], 0.1);Evolib.play(0)"&gt;mutate&lt;/buttonbr&gt;
  &lt;brbr&gt;
  &lt;button onclick="Evolib.play(4)"&gt;play 4&lt;/buttonbr&gt;
    &lt;button onclick="Evolib.evolve([4], 0.1);Evolib.play(0)"&gt;mutate&lt;/buttonbr&gt;
&lt;brbr&gt;
  &lt;brbr&gt;
  &lt;button onclick="Evolib.stop()"&gt;stop&lt;/buttonbr&gt;
  &lt;button onclick="Evolib.newPopulation(5, 30);  Evolib.play(0)"&gt;new sounds&lt;/buttonbr&gt;
</code>
</pre>
<p class = "tutorial-text">
Now you can click on the mutate button to select which of the sounds you want. After clicking mutate, click on the play buttons to hear mutations of the sound you selected for mutation. Keep going and you'll gradually breed a set of sounds. If they change too little, increase the mutation rate:
</p>
<pre>
  <code>
Evolib.evolve([0], 0.2); // 0.2 is a higher mutation rate
</code>
</pre>
<p class = "tutorial-text">
Here is the complete code:
</p>
<p class = "tutorial-text">
  <iframe class = "embedded-tutorial-code" src={{concat url "/code/723f4078-b9c2-de8d-4970-fb41609213e2?embed=true&showCode=true"}} allow="microphone" scrolling="no" style="width: 100%; height: 350px; overflow: hidden;">what?</iframe>
<a href = {{concat url "/723f4078-b9c2-de8d-4970-fb41609213e2"}}>Open Project</a>
</p>
<h2>
Next part:
</h2>
<p class = "tutorial-text">
In the next part, we'll look at how to add a record button, how to gain more control of the evolutionary process and how to change the characteristics of the available modules.
</p>

{{/if}}
</div>
{{else}}
<div id = "tutorial-container">
<h2>Guides</h2>
<h3>Simple code examples of MIMIC libraries and ML concepts</h3>
<p class = "tutorial-text">
Each guide below uses a MIMIC library to demonstrate how to use machine intelligence to make music in the browser
</p>
<div id = "guide-container">
{{#each model as |guide|}}
  <a class = "guide-link" href = {{guide.url}}>{{guide.name}}</a><br>
{{/each}}
</div>
</div>
{{/if}}
