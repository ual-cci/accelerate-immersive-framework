<h2>Learner.js</h2>
<p class = "tutorial-text">
This is a quick walkthrough of how to use Learner.js on the MIMIC platform to quickly build your own simple machine learning tools.
</p>
<p class = "tutorial-text">
Learner.js provides an interface that allows you to easily record in examples of input and output pairings into a dataset that is saved locally in your browser. You can then train a model to respond with new outputs when you provide new inputs. We take care of all the storage, threading and GUI needs and all you have to do is pick what you want to control is what!
</p>

<p class = "tutorial-text">
If you want to follow along to this tutorial with a simple project, check out the <a href = "https://mimicproject.com/code/3738a892-330f-15ae-673e-5cb38f25a8e8"> Mouse XY Example</a>. Otherwise, you can make a new project from scratch and follow along that way.
</p>
<p class = "tutorial-text">
You can also find <a href = "https://mimicproject.com/inputs">a bunch of fun inputs</a>
</p>

<p class = "tutorial-heading">
1. Set up
</p>
<p class = "tutorial-text">
Include the library
</p>
<pre>
<xmp>
&lt;script src = "https://mimicproject.com/libs/learner.v.0.2.js"&gt;&lt;/script&gt;
</xmp>
</pre>
<p class = "tutorial-text">
Initialise the object
</p>
<pre>
<code>
const learner = new Learner();
</code>
</pre>
<p class = "tutorial-heading">
2.  Add GUI
</p>
<p class = "tutorial-text">
Give the learner the HTML element you want to attach the GUI to
<pre>
<code>
learner.addGUI(document.getElementById("dataset"));
</code>
</pre>
</p>
<p class = "tutorial-text">
When you run the program you will see that you are given a number of simple controls including record, train, run, clear. You are also given a set of controls to set the output state. For classifiers, this will be a dropdown menu. For Regression models, this will be a slider per output.
</p>
<p class = "tutorial-heading">
3. Add Model
</p>
<p class = "tutorial-text">
You can now specify a model to use. For regression (continuous values), use the code below, specifying the number of outputs you want to control.
</p>
<pre>
<code>
learner.addRegression(3)
</code>
</pre>
<p class = "tutorial-text">
For classification (discrete states), use the code below specifying the number of classes you wish to discriminate between
</p>
<pre>
<code>
learner.addClassification(4)
</code>
</pre>
<p class = "tutorial-heading">
4. Add data
</p>
<p class = "tutorial-text">
The learner expects to receive examples that are paired input and output mappings. For example, you could add the x and y position of the mouse every time it is moved (the input), paired with the current colour of canvas object (the output).
</p>
<p class = "tutorial-text">
It is important to note that one piece of code (below) serves two purposes.
<ul>
  <li>If you are <strong>recording</strong>, every time you add a new example the pairing is stored in the dataset. To use the values of the Learner.js GUI (the regression sliders or classification dropdown) as output labels, you can call "learner.y"</li>
  <li>If you are <strong>running</strong>, just the input is used and given to the model, which then provides a new output based on the data it has seen.</li>
</ul>
</p>
<p class = "tutorial-text">
Use the code below to add and array of inputs and an array of outputs.
</p>
<pre>
<code>
const whenYouReceiveNewInputs = (newInputs)=> {
  //Match inputs with output labels you have collected
  learner.newExample(newInputs, outputs);
}

//OR//

const whenYouReceiveNewInputs = (newInputs)=> {
  //Use the current values of the GUI as output labels
  learner.newExample(newInputs, learner.y);
}
</code>
</pre>
<p class = "tutorial-text">
Each dataset is specific to a MIMIC documents, and your dataset will be saved in the browser's IndexedDB. This means that will persist beyond reruns of the project, refreshes of the page and closing of the browser window (in public mode). You will <strong>loose</strong> the data if you clear your cache, or if you close the window and you are in private / incognito mode.
</p>
<p class = "tutorial-text">
You can also use the following functions to provide a count in to recording, this will delay the start of recording the given number of seconds after the "record" button has been pressed. You can also choose to limit recording time, again specifying a given number of seconds beforehand you want to record for before it is automatically shut off. Both default to 0.
<pre>
<code>
learner.setCountIn(5)
learner.setRecordLimit(5)
</code>
</pre>
</p>
<p class = "tutorial-heading">
5. Respond to outputs
</p>
<p class = "tutorial-text">
Finally, you should specify a function the is called when an a new output value is available. Again this function serves two purposes with one piece of code.
<ul>
  <li>When you are  <strong>not running</strong>, this will be in response to the GUI (the dropdown or the sliders) changing. You can save these in a variable to use later, or if you need to access them they are saved in the learner.y variable.</li>
  <li>If you are  <strong>running</strong>, this will be the models response to an input. </li>
</ul>
The function returns an array of output values. Obviously, you can do something more fun.
</p>
<pre>
<code>
learner.onOutput = (data)=> {
  y = data;
});
</code>
</pre>
<p class = "tutorial-heading">
Web Audio Outputs (MaxiInstruments)
</p>
<p class = "tutorial-text">
We have a complimentry set of synthesisers and samplers, backed by AudioWorklets to reduce interference between the machine learning and the audio. They are designed to easily combine with Learner.js and <a href = "https://mimicproject.com/guides/maxi-instrument">you can learn about them</a>
</p>
<p class = "tutorial-heading">
External Outputs
</p>
<p class = "tutorial-text">
  You can use the examples below to output with MIDI control message or OSC messages to control music or visual programs locally (Max/MSP, Supercollider, openFrameworks, Processing, PD etc....)
<ul>
<li><a href = "https://mimicproject.com/code/034ea170-483e-229a-f0e2-837d76c721c0">MIDI example sketch </a></li>This uses WebMidi to send the output values as control changes. Note WebMidi is curently only supported in Chrome. You can send to external devices or connect to your internal MIDI bus, <a href = "https://help.ableton.com/hc/en-us/articles/209774225-How-to-setup-a-virtual-MIDI-bus">this is a good resource for how to do that</a>. First refresh devices, then select your output source and channel from the dropdown.
<li><a href = "https://mimicproject.com/code/247e4538-0366-b735-9052-0e875a96a140">OSC example sketch </a></li> As you cannot OSC directly form a browser, this connects to a local Node.js program via webosckets then forwards the data out via OSC, where you can do with it what you will.
<ol>
  <li>First, <a href = "https://github.com/Louismac/osc-repeater">download the node program</a>. </li>
  <li>Install <a href = "http://(https//nodejs.org/en/download/)">node </a> if you dont have it on your laptop</li>
  <li>In the terminal (OSX) or command-prompt (windows), navigate (cd) to the folder you unzipped to code to and run
  <pre>
  <code>
    npm install & node osc-repeater.js
  </code>
  </pre>
  </li>
  <li>This should now forward the outputs from MIMIC to the port you have specfied in the code (defaults to 57120).</li>
</ol>
</ul>
</p>
<p class = "tutorial-heading">
6. Now be free and make amazing projects!
</p>
<p class = "tutorial-text">You can find <a href = "https://mimicproject.com/inputs">a bunch of fun inputs</a>
</p>
<p class = "tutorial-text">
You can also see the source and instructions for running the library locally or in your own projects away from the MIMIC platform in <a href = "https://gitlab.doc.gold.ac.uk/MIMIC/learner-js">this repository</a>.
</p>
