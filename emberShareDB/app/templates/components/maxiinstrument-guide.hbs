<h2>MaxiInstruments</h2>
<p class = "tutorial-text">
MaxiInstruments is a class of simple synths and samplers that are designed to so that their parameters can be easily controlled using the <a href = "https://mimicproject.com/guides/learner">Learner.js</a> library. They are AudioWorklets backed so do not get interrupted by beefy feature extractors one might use an an input or the running of a model to do the mapping.
</p>
<p class = "tutorial-text">
Previously, Chromium-based browsers (around Chrome 79) had a bug that may cause slight crackling in Audio Worklet based programs. However, we now believe this bug to be fixed (Chrome 80 onwards). If you are experiencing this issue, <a href = "https://bugs.chromium.org/p/chromium/issues/detail?id=1033493#c42">you can follow the bug </a>and also download and run <a href ="https://www.google.com/chrome/canary/" >Canary (newer beta version of Chrome)</a> or <a href = "https://www.slimjet.com/chrome/google-chrome-old-version.php">older versions of Chrome</a> to get better results.
</p>
<p class = "tutorial-heading">
1. Set up
</p>
<p class = "tutorial-text">
Include the library
</p>
<pre>
<code>
&lt;script src = "https://mimicproject.com/libs/maxiInstruments.v.0.4.js"&gt;&lt;/script&gt;
</code>
</pre>
<p class = "tutorial-text">
Initialise the object
</p>
<pre>
<code>
const maxiInstruments = new MaxiInstruments();
</code>
</pre>

<p class = "tutorial-heading">
2. Add the GUI
</p>
<p class = "tutorial-text">
Give the instruments the HTML element you want to attach the GUI to
</p>
<pre>
<code>
instruments.guiElement = document.getElementById("synths");
</code>
</pre>
<p class = "tutorial-heading">
3. Load the modules
</p>
<p class = "tutorial-text">
You need to load in the audio workout modules, when this is done you can start adding instruments
</p>
<pre>
<code>
instruments.loadModules().then(()=> {

//Add instruments here!!

});
</code>
</pre>
<p class = "tutorial-heading">
4. MaxiSynth
</p>
<p class = "tutorial-text">
MaxiSynth is a simple subtractive synthesiser.
</p>
<p class = "tutorial-text">
Use the code below to add one synth, with the synths being stored in the instrument object’s .synth property. You can add as many as you like, depending on how much your set up can handle. Each will have its own GUI.
</p>
<pre>
<code>
instruments.addSynth();
</code>
</pre>
<p class = "tutorial-text">
You can either have a two tone synthesiser where the frequency of each oscillator is controller by a slider OR you can have a polyphonic (up to 8 voice) synth where the frequency is specified by either a provided sequence or MIDI controller. Defaults to false.
</p>
<pre>
<code>
instruments.synths[0].useFreqSliders(true);
</code>
</pre>
<p class = "tutorial-text">
You can then pick which parameters of the synth you can like to be controlled by your model by passing an array of names. The code below shows how you would select the frequencies of the two oscillators to be controlled by your regression model.
</p>
<pre>
<code>
instruments.synths[0].mapped = ["frequency", "frequency2"];
</code>
</pre>
<p class = "tutorial-text">
The synth also has a Randomise button that will select random values for your selected parameters. This can help you find fun sounds when making your own mappings.
</p>
<p class = "tutorial-heading">
5. MaxiSampler
</p>
<p class = "tutorial-text">
Add a sampler using the code below. Similarly to the MaxiSynth, you can have as many samplers you want (each can hold 8 samples). They are stored in the instrument object’s samplers property. Each will have its own GUI, showing the controls for 4 samples at a time.
</p>
<p class = "tutorial-text">
Load each sample by passing the url and an index (of the 8 slots) to store the sample.
</p>
<pre>
<code>
instruments.samplers[0].loadSample("909.wav", 0);
</code>
</pre>
<p class = "tutorial-text">
Similarly to the MaxiSynth, you can then pick which parameters of the synth you can like to be controlled by your model by passing an array of names. Each samples parameters are identified by an underscored index following the name (this is also visible on the GUI).
</p>
<pre>
<code>
instruments.samplers[0].mapped = ["rate_0", "gain_1"];
</code>
</pre>
<p class = "tutorial-heading">
6. Adding the Model
</p>
<p class = "tutorial-text">
You can now start mapping your chosen parameters to a given input using the Learner.js library. More information about this can be found in this <a href = "https://mimicproject.com/guides/learner">guide</a>. The instruments will work out how many outputs you need, given the mapped parameters you have specified. The second argument of "false" tells Learner.js that you don't need an additional GUI for your regression model, because you have the GUI provided by the instrument.
</p>

<pre>
<code>
learner.addRegression(instruments.getNumMappedOutputs(), false);
</code>
</pre>
<p class = "tutorial-heading">
7. Providing the input
</p>
<p class = "tutorial-text">
When you are providing a new example, the instruments object will give you all the current values of the mapped parameters of all your instruments with the getMappedOutputs() function
</p>
<p class = "tutorial-text">
It is important to note that one piece of code (below) serves two purposes.
<ul>
  <li>If you are <strong>recording</strong>, every time you add a new example the pairing is stored in the dataset.</li>
  <li>If you are <strong>running</strong>, just the input is used and given to the model, which then provides a new output based on the data it has seen.</li>
</ul>
</p>
<pre>
<code>
const whenYouReceiveNewInputs = (newInputs)=> {
  //Match them with outputs (instrument parameters)
  learner.newExample(newInputs, instruments.getMappedOutputs());
}
</code>
</pre>
<p class = "tutorial-heading">
8. Responding to the output
</p>
<p class = "tutorial-text">
The instruments object can update the mapped parameters provided by the model (in response to inputs) using the updateMappedOutputs(data) function.
</p>
<pre>
<code>
learner.onOutput = (data)=> {
  //Update the instruments parameters with output of model
  instruments.updateMappedOutputs(data);
}
</code>
</pre>
<p class = "tutorial-heading">
9. Controlling the Instruments
</p>
<p class = "tutorial-text">
Both samplers and synths respond to simple noteon, noteoff commands. If you are using controlling the frequency of your synth externally, you should also provide a frequency. Second velocity argument is optional.
</p>
<pre>
<code>
instruments.synths[0].noteon(440, 127);
instruments.synths[0].noteoff(440);
</code>
</pre>
<p class = "tutorial-text">
For samplers, noteoffs are not necessary and you provide the index of the sample you wish to trigger. For eaxmple, the code below would trigger the sample in the third slot of the first sampler. You only require a noteon for samplers as they are one-shot. Second velocity argument is optional.
</p>
<pre>
<code>
instruments.samplers[0].noteon(2, 60);
instruments.samplers[0].noteon(2);
</code>
</pre>
<p class = "tutorial-text">
You can also specify a sequence yourself. We use broadly the same structure of NoteSequence used by Google's Magenta project making the libraries nicely interchangeable. We have chosen to adopt the MIDI standard of 24 ticks per beat.
</p>
<p class = "tutorial-text">
The MaxiInstruments object has a global clock where you can specify a tempo (bpm) and a loop point (in ticks or beats). All note-ons are released at the end of the loop as a safety measure. You can also play / pause with playPause(), or rewind() to reset the clock to 0.
</p>
<pre>
<code>
instruments.setTempo(80);
instruments.setLoop(96); //4 Beats
instruments.setLoopBeats(4); //Equivalent in beats
instruments.playPause(); //Toggle playback
instruments.rewind(); //Reset clock to 0
</code>
</pre>
<p class = "tutorial-text">
The MaxiInstruments object also has a callback called onTick(), called on every tick of the clock. As the callback is being executed on the main thread, it does not have any of the advantages of the separate audio thread where the clock resides, as such may be effected by interruptions. It relies on the messaging system between threads and whilst reasonably reliable, it is not advised to use this for time critical actions and it is not guaranteed to be sample-accurately-in-sync with events being triggered on the audio thread.
</p>
<pre>
<code>
instruments.setOnTick((playHead)=>{
  console.log(playHead)
})
</code>
</pre>
<p class = "tutorial-text">
You can then define sequences in terms of note ons and noteoff in ticks, and set them to a specific synth or sampler. Samplers are oneshot so only require a start. Velocity is optional.
</p>
<pre>
	<code>
const synthSeq = {
  notes:[
    {pitch:60, start:0, end:12, velocity:127},
    {pitch:67, start:49, end:72, velocity:60},
  ],
};
instruments.synths[0].setSequence(synthSeq);

const samplerSeq = {
  notes:[
    {pitch:0, start:0, velocity:127},
    {pitch:1, start:49},
  ],
};
instruments.samplers[0].setSequence(samplerSeq);
	</code>
</pre>
<p class = "tutorial-text">
You can also input sequences generated from Magenta directly into the synths. Below is an example using one of Magenta's pretrained recurrent neural networks to complete the a given seqeunce, and playing it directly on a MaxiSynth. First import the Magenta library.
</p>
<pre>
<code>
&lt;script src = "https://cdn.jsdelivr.net/npm/@magenta/music@1.11.0"&gt;&lt;/script&gt;
</code>
</pre>
<p class = "tutorial-text">
In order to get a continued seqeunce from Magenta's pretrained models, you can specify a seed sequence given
<ul>
	<li>A tempo</li>
	<li>A definition of stepsPerQuarter. We define time in steps and this tells us how many represent a quarter note / crotchet</li>
	<li>An array of notes objects, including pitch (MIDI), a start time and end time each in steps</li>
	<li>A total length, also in steps</li>
</ul>
See the code below as an example
</p>
<pre>
	<code>
const inputSeq = {
  tempos: [{time:0, qpm:80}],
  notes:[
    {pitch:60, quantizedStartStep:0, quantizedEndStep:2},
    {pitch:67, quantizedStartStep:4, quantizedEndStep:6}
  ],
  quantizationInfo:{stepsPerQuarter: 4},
  totalQuantizedSteps:32,
};
	</code>
</pre>
<p class = "tutorial-text">
Then you can feed to Magenta, and set the returned sequence directly to synth.
</p>
<pre>
	<code>
let rnn = new mm.MusicRNN(MODEL_URL);
rnn.initialize().then(()=> {
  rnn.continueSequence(inputSeq, 32, 1.5).then((newSeq)=> {

    //Set the tempo and loop point
    instruments.setTempo(newSeq.tempos[0].qpm);
    const loop = 24 / newSeq.quantizationInfo.stepsPerQuarter * newSeq.totalQuantizedSteps;
    instruments.setLoop(loop)

    //Set the note sequence
    instruments.synths[0].setSequence(newSeq);
  });
});
	</code>
</pre>
<h2>Example Projects</h2>
<p class = "tutorial-text">
Here are some examples sequenced in various ways, mostly using body tracking as an input.
<ul>
  <li><a href = "https://mimicproject.com/code/73d93516-e0de-a85c-5fc7-c6cc03f4666b">MIDI</a></li> This example allows you to play notes into the synth using an external MIDI instrument, whilst mapping the parameters to a different input. Note WebMidi is curently only supported in Chrome. You can connect to external devices or connect to your internal MIDI bus, <a href = "https://help.ableton.com/hc/en-us/articles/209774225-How-to-setup-a-virtual-MIDI-bus">this is a good resource for how to do that</a>. If you were generating notes in an another program (Max/MSP, Supercollider, PD), this would be a good way to trigger MaxiSynth. First refresh devices, then select your MIDI source from the dropdown.
  <li><a href = "https://mimicproject.com/code/d57c9d9b-284d-9ab3-8118-e7c33eafeeaf">Nexus Sequencer</a></li> This allows you use a one-shot sequencer to program a tune yourself, whilst mapping the parameters of the synths to one of the inputs.
  <li><a href = "https://mimicproject.com/code/f6bdb7ad-4cb0-8652-0dee-f0c7db9fede5">Hand coded sequence</a></li> This shows you how you can program in your own sequence by hand.
  <li><a href = "https://mimicproject.com/code/fa99819f-775c-2552-198c-2340739a1b5c">Magenta Generated sequence</a></li> This shows you how you can generate a sequence using Google's Magenta models and plug that straight into a synth.
  <li><a href = "https://mimicproject.com/code/1cc85746-67d2-0cef-7f69-a238c6d2b489">MIDI File playback</a></li> This shows you how you can upload a MIDI File as an asset then play on a MaxiSynth.
</ul>
</p>
<p class = "tutorial-text">
You can find a <a href = "https://mimicproject.com/inputs">bunch of fun inputs</a>
</p>
<p class = "tutorial-text">
You can also see the source and instructions for running the library locally or in your own projects away from the MIMIC platform in <a href = "https://gitlab.doc.gold.ac.uk/MIMIC/learner-js">this repository</a>.
</p>
